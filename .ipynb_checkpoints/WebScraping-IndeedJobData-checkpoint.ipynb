{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e92f242-c8ab-4854-9bf5-e8c6bfbe8a65",
   "metadata": {},
   "source": [
    "### Indeed Job Data Project\n",
    "\n",
    "##### This project aims to practice web scraping using the BeautifulSoup library, it scrapes the in.indeed.com and looks for job opportunities that match the job title and location that a job seeker input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf50b29-a881-4766-890b-e4bf11f63622",
   "metadata": {},
   "source": [
    "// First of all, install required packages if not done so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106f9cf7-2d37-482f-b613-feeb2b8018c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module to pull data out of html and xml files\n",
    "#!pip install bs4\n",
    "\n",
    "# request to allow HTTP/1.1 request to be sent, not built-in in Python\n",
    "#!pip install requests\n",
    "\n",
    "#!pip install selenium"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35d3266b-59ee-4d5e-88dd-0e04f42af300",
   "metadata": {},
   "source": [
    "1. Go to in.indeed.com and search for a job at a location: data scientist internship at Uttar Pradesh<br>\n",
    "2. Here is the URL we got: \" https://<span style=\"color: green;\">in.indeed.com/jobs</span>?q=<span style=\"color: red;\">Data+Scientist+Internship</span>&l=<span style=\"color: red;\">Uttar+Pradesh</span> \"<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ca7524e-132e-4066-a291-868b9255afca",
   "metadata": {},
   "source": [
    "<img src=\"25D85E0C-9362-4200-998F-A0B26298CD61.jpeg\" alt=\"sample\" style = \"width:700px; height: auto;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2012de76-0785-43c8-b245-728a9affa265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the job title, keywords, or company:  data science intern\n",
      "Enter the city, state, or zipcode:  Chennai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking for jobs for you on in.indeed.com...\n",
      "Almost there... \n",
      "\n",
      "Woohoo! Found 8 jobs for you! \n",
      "\n",
      "Company Name:  Akra Tech\n",
      "Company Location:  Chennai, Tamil Nadu\n",
      "Job:  Interns - AI Developer\n",
      "----------------------------------\n",
      "Company Name:  Fifth Generation Technologies\n",
      "Company Location:  Chennai, Tamil Nadu\n",
      "Job:  Programming Interns (3-4 months)\n",
      "----------------------------------\n",
      "Company Name:  Qualcomm\n",
      "Company Location:  Chennai, Tamil Nadu\n",
      "Job:  1 year Internship_SW_CDC\n",
      "----------------------------------\n",
      "Company Name:  MercuryMinds\n",
      "Company Location:  Remote in Chennai, Tamil Nadu\n",
      "Job:  Data Science Intern\n",
      "----------------------------------\n",
      "Company Name:  HERE AND NOW - The French Institute\n",
      "Company Location:  Aminjikarai, Chennai, Tamil Nadu\n",
      "Job:  AI Intern\n",
      "----------------------------------\n",
      "Company Name:  GuiRes Solutions Pvt Ltd\n",
      "Company Location:  Nungambakkam, Chennai, Tamil Nadu\n",
      "Job:  Statistical Intern\n",
      "----------------------------------\n",
      "Company Name:  Bahwan Cybertek Group\n",
      "Company Location:  Chennai, Tamil Nadu\n",
      "Job:  Intern\n",
      "----------------------------------\n",
      "Company Name:  Zet Realty\n",
      "Company Location:  Chennai, Tamil Nadu\n",
      "Job:  ERP Executive Internship\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "\n",
    "# Function to get rendered HTML using Selenium (get dynamic data from page)\n",
    "def get_rendered_html(url):\n",
    "    try:\n",
    "        # Open Chrome and get to the linked page\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait only until the job listings are visible or timeout occurs\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"jcs-JobTitle\"))\n",
    "        )\n",
    "\n",
    "        # Get the page source\n",
    "        rendered_html = driver.page_source\n",
    "        status = \"Success\"  # Job titles found\n",
    "    except TimeoutException:\n",
    "        # Handle case where no job titles are found\n",
    "        rendered_html = None\n",
    "        status = \"No job titles found\"\n",
    "    finally:\n",
    "        # Ensure Chrome is closed in all cases\n",
    "        driver.quit()\n",
    "\n",
    "    return {\"html\": rendered_html, \"status\": status}\n",
    "\n",
    "# Parse HTML using BeautifulSoup\n",
    "def html_code(url):\n",
    "    response = get_rendered_html(url)\n",
    "    if response[\"status\"] == \"Success\":\n",
    "        soup = BeautifulSoup(response[\"html\"], 'html.parser')\n",
    "        return soup, response[\"status\"]\n",
    "    else:\n",
    "        return None, response[\"status\"]\n",
    "\n",
    "# Filter job data using find_all\n",
    "def job_data(soup):\n",
    "    # Extract job titles based on the new class\n",
    "    result_1 = [item.get_text().strip() for item in soup.find_all(\"a\", class_=\"jcs-JobTitle\")]\n",
    "    return result_1\n",
    "\n",
    "# Filter company data using find_all\n",
    "def company_data(soup):\n",
    "    # Extract company names based on the span with specific class\n",
    "    result_2 = [item.get_text().strip() for item in soup.find_all(\"span\", class_=\"css-1h7lukg eu4oa1w0\")]\n",
    "    return result_2\n",
    "\n",
    "# Filter company location using find_all\n",
    "def location_data(soup):\n",
    "    # Extract company locations based on the div with specific class\n",
    "    result_3 = [item.get_text().strip() for item in soup.find_all(\"div\", class_=\"css-1restlb eu4oa1w0\")]\n",
    "    return result_3\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Ask the user to input data for URL\n",
    "    job = input(\"Enter the job title, keywords, or company: \").strip()\n",
    "    location = input(\"Enter the city, state, or zipcode: \").strip()\n",
    "    print(\"\\nLooking for jobs for you on in.indeed.com...\\nAlmost there... \\n\")\n",
    "    url = f\"https://in.indeed.com/jobs?q={job}&l={location}\"\n",
    "\n",
    "    # Get HTML and parse it\n",
    "    soup, status = html_code(url)\n",
    "\n",
    "    if status == \"Success\":\n",
    "        # Extract the job data\n",
    "        job_res = job_data(soup)\n",
    "\n",
    "        if len(job_res) > 0:\n",
    "            # Extract the company data\n",
    "            company_res = company_data(soup)\n",
    "\n",
    "            # Extract the location data\n",
    "            loc_res = location_data(soup)\n",
    "\n",
    "            print(f\"Woohoo! Found {len(job_res)} jobs for you! \\n\")\n",
    "            # Print the job results\n",
    "            for i in range(len(job_res)):\n",
    "                print(\"Company Name: \", company_res[i])\n",
    "                print(\"Company Location: \", loc_res[i])\n",
    "                print(\"Job: \", job_res[i])\n",
    "                if i < len(job_res) - 1:\n",
    "                    print(\"----------------------------------\")\n",
    "        else:\n",
    "            print(\"Oops! No job listings found on in.indeed.com.(1)\")\n",
    "    else:\n",
    "        print(\"Oops! No job listings found on in.indeed.com.(2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f36e54-e0d9-4024-ae1b-758e2239d9bb",
   "metadata": {},
   "source": [
    "* Note: If the website requires additional verification and closed itself, try close this file and open a new one..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
